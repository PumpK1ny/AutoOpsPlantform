"""QQæœºå™¨äººAIå¯¹è¯æ¨¡å— - æ”¯æŒGLM-4.6Vå¤šæ¨¡æ€ã€è¡¨æƒ…åŒ…toolcall"""

import os
import json
import base64
import re
from dotenv import load_dotenv
from zhipuai import ZhipuAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·¯å¾„é…ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_DIR = os.path.join(BASE_DIR, "chat_history")
SYSTEM_PROMPT_FILE = os.path.join(BASE_DIR, "system_prompt.txt")

# å‹ç¼©é˜ˆå€¼ï¼ˆtokenæ•°ï¼Œå¤§çº¦ä¼°ç®—ï¼‰
COMPRESS_THRESHOLD = 10000

# ç¡®ä¿å†å²è®°å½•ç›®å½•å­˜åœ¨
os.makedirs(HISTORY_DIR, exist_ok=True)


def load_system_prompt() -> str:
    """ä»æ–‡ä»¶åŠ è½½system prompt"""
    if os.path.exists(SYSTEM_PROMPT_FILE):
        with open(SYSTEM_PROMPT_FILE, "r", encoding="utf-8") as f:
            return f.read().strip()
    return "ä½ æ˜¯QQç¾¤é‡Œçš„èŠå¤©æœºå™¨äººï¼Œæ€§æ ¼æ´»æ³¼å¯çˆ±ï¼Œå–œæ¬¢ç”¨è¡¨æƒ…åŒ…ã€‚è¯·ç”¨ç®€æ´å‹å¥½çš„ä¸­æ–‡å›ç­”ã€‚"


def load_history(user_openid: str) -> tuple[list, str]:
    """
    åŠ è½½ç”¨æˆ·å†å²å¯¹è¯
    
    Returns:
        (å¯¹è¯è®°å½•åˆ—è¡¨, å‹ç¼©æ‘˜è¦)
    """
    history_file = os.path.join(HISTORY_DIR, f"{user_openid}.json")
    if os.path.exists(history_file):
        with open(history_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, dict):
                return data.get("history", []), data.get("summary", "")
            return data, ""
    return [], ""


def save_history(user_openid: str, history: list, summary: str = None):
    """
    ä¿å­˜ç”¨æˆ·å†å²å¯¹è¯
    
    Args:
        history: å¯¹è¯è®°å½•åˆ—è¡¨ï¼ˆä¸åŒ…å«systemï¼‰
        summary: å‹ç¼©æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
    """
    history_file = os.path.join(HISTORY_DIR, f"{user_openid}.json")
    
    if summary:
        # ä¿å­˜ä¸ºå­—å…¸æ ¼å¼ï¼ˆåŒ…å«æ‘˜è¦ï¼‰
        data = {"history": history, "summary": summary}
    else:
        # ä¿å­˜ä¸ºåˆ—è¡¨æ ¼å¼ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        data = history
    
    with open(history_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def estimate_tokens(text: str) -> int:
    """ä¼°ç®—tokenæ•°"""
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    english_words = len(re.findall(r'[a-zA-Z]+', text))
    others = len(text) - chinese_chars - sum(len(w) for w in re.findall(r'[a-zA-Z]+', text))
    return int(chinese_chars * 1.5 + english_words * 1.2 + others * 0.5)


def calculate_context_tokens(context: list) -> int:
    """è®¡ç®—ä¸Šä¸‹æ–‡çš„tokenæ•°"""
    total = 0
    for msg in context:
        content = msg.get("content", "")
        if isinstance(content, str):
            total += estimate_tokens(content)
        elif isinstance(content, list):
            for item in content:
                if item.get("type") == "text":
                    total += estimate_tokens(item.get("text", ""))
                else:
                    total += 1000
    return total


class ChatAI:
    """å¤šæ¨¡æ€AIå¯¹è¯ç±» - æ”¯æŒGLM-4.6Vã€å›¾ç‰‡ç†è§£ã€è¡¨æƒ…åŒ…toolcall"""



    def __init__(self, user_openid: str):
        self.user_openid = user_openid
        self.client = ZhipuAI(api_key=os.getenv("ZHIPU_API_KEY"))
        self.model = os.getenv("QQCHAT_DEFAULT_MODEL", "glm-4.6v-flash")
        self.base_system_prompt = load_system_prompt()
        self.system_prompt = self.base_system_prompt

        # åŠ è½½å¯¹è¯è®°å½•å’Œå‹ç¼©æ‘˜è¦ï¼ˆåªåŠ è½½user/assistantæ¶ˆæ¯ï¼Œä¸åŒ…å«systemï¼‰
        self.dialog_history, self.summary = load_history(user_openid)

        self.is_compressing = False
        self.compress_callback = None

    def _build_context(self) -> list:
        """æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼ˆsystem + å¯¹è¯ï¼‰"""
        context = []
        
        # 1. system prompt
        context.append({"role": "system", "content": self.system_prompt})
        
        # 2. å¯¹è¯å†å²ï¼ˆuser/assistantæ¶ˆæ¯ï¼‰
        context.extend(self.dialog_history)
        return context

    def set_compress_callback(self, callback):
        """è®¾ç½®å‹ç¼©å®Œæˆå›è°ƒ"""
        self.compress_callback = callback

    def check_and_compress(self) -> bool:
        """æ£€æŸ¥å¹¶æ‰§è¡Œå‹ç¼©"""
        context = self._build_context()
        tokens = calculate_context_tokens(context)
        if tokens < COMPRESS_THRESHOLD:
            return False

        self.is_compressing = True
        try:
            from message_push.QQ.ai_chat_compress import compress_context
            summary = compress_context(context)
            self.summary = summary
            
            # ä¿å­˜ä¸ºassistantæ¶ˆæ¯
            summary_message = {"role": "assistant", "content": f"ã€å†å²å¯¹è¯æ‘˜è¦ã€‘\n{summary}"}
            save_history(self.user_openid, [summary_message])
            self.dialog_history = [summary_message]
            
            self.is_compressing = False
            if self.compress_callback:
                self.compress_callback("âœ… ä¸Šä¸‹æ–‡å‹ç¼©å®Œæˆï¼å·²ä¿ç•™å…³é”®ä¿¡æ¯ï¼Œå¯ä»¥ç»§ç»­å¯¹è¯äº†~")
            return True
        except Exception as e:
            self.is_compressing = False
            if self.compress_callback:
                self.compress_callback(f"âš ï¸ ä¸Šä¸‹æ–‡å‹ç¼©å¤±è´¥: {e}")
            return False

    def chat(self, message: str, image_url: str = None, image_base64: str = None) -> dict:
        """
        å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤
        
        Returns:
            dict: {"text": å›å¤æ–‡æœ¬}
        """
        if self.is_compressing:
            return {"text": "â³ æ­£åœ¨å‹ç¼©å†å²å¯¹è¯ï¼Œè¯·ç¨ç­‰..."}

        if not image_url and not image_base64:
            if self.check_and_compress():
                return {"text": "ğŸ”„ æ£€æµ‹åˆ°å¯¹è¯å†å²è¾ƒé•¿ï¼Œæ­£åœ¨è‡ªåŠ¨å‹ç¼©ä¸Šä¸‹æ–‡..."}

        # æ„å»ºæ¶ˆæ¯
        if image_url or image_base64:
            content = []
            if image_url:
                content.append({"type": "image_url", "image_url": {"url": image_url}})
            elif image_base64:
                content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}})
            if message:
                content.append({"type": "text", "text": message})
            user_message = {"role": "user", "content": content}
        else:
            user_message = {"role": "user", "content": message}

        self.dialog_history.append(user_message)

        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        context = self._build_context()

        # è°ƒç”¨APIï¼Œå¸¦é‡è¯•æœºåˆ¶
        max_retries = 3
        retry_delay = 4  # ç§’
        response = None
        
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=context,
                    max_tokens=2048,
                    temperature=0.7,
                    top_p=0.7,
                    stream=False,
                    thinking={"type": "disabled"}
                )
                break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg or "1305" in error_msg or "è¯·æ±‚è¿‡å¤š" in error_msg:
                    if attempt < max_retries - 1:
                        import time
                        time.sleep(retry_delay * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
                        continue
                raise  # é429é”™è¯¯æˆ–é‡è¯•æ¬¡æ•°ç”¨å°½ï¼ŒæŠ›å‡ºå¼‚å¸¸
        
        if response is None:
            return {"text": "â³ APIè¯·æ±‚ç¹å¿™ï¼Œè¯·ç¨åå†è¯•~"}

        reply = response.choices[0].message.content
        reply = reply.strip() if reply else ""
        
        # å»é™¤XMLæ ‡ç­¾ï¼ˆå¦‚</arg_value>ç­‰ï¼‰
        import re
        reply = re.sub(r'</?\w+>', '', reply)

        # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
        self.dialog_history.append({"role": "assistant", "content": reply})

        save_history(self.user_openid, self.dialog_history)

        return {"text": reply}


# å†…å­˜ä¸­çš„ä¼šè¯ç¼“å­˜
_sessions = {}


def chat_with_user(user_openid: str, message: str, image_url: str = None,
                   image_base64: str = None, compress_callback=None) -> dict:
    """
    ä¸æŒ‡å®šç”¨æˆ·å¯¹è¯
    
    Returns:
        dict: {"text": å›å¤æ–‡æœ¬}
    """
    if user_openid not in _sessions:
        _sessions[user_openid] = ChatAI(user_openid)

    if compress_callback:
        _sessions[user_openid].set_compress_callback(compress_callback)

    return _sessions[user_openid].chat(message, image_url, image_base64)
